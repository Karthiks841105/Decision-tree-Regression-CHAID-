{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###DecisionTreeRegression(CHAID)\n",
        "####Decision tree regression using CHAID (Chi-squared Automatic Interaction Detection) is a popular algorithm for building regression trees. In this approach, the algorithm recursively partitions the data into smaller subsets based on the predictor variables that have the strongest association with the target variable."
      ],
      "metadata": {
        "id": "GjMV4Mp3eQtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the step-by-step algorithm for decision tree regression:\n",
        "\n",
        "**step1**:Start with the entire dataset as the root node.\n",
        "\n",
        "**step2**:Choose a predictor variable that has a significant association with the target variable, and perform a chi-squared test to determine the best way to split the data into two subsets based on the values of that predictor variable.\n",
        "\n",
        "**step3**:If the chi-squared test indicates a significant difference between the subsets, create two child nodes and repeat steps 2-3 for each of the child nodes. If the chi-squared test does not indicate a significant difference, stop and make the current node a leaf node.\n",
        "\n",
        "**step4**:When creating child nodes, repeat the process until a stopping criterion is reached. This could be a maximum tree depth, a minimum number of samples in a leaf node, or a minimum improvement in the chi-squared statistic.\n",
        "\n",
        "**step5**:Continue building the tree until all the nodes have been split or the stopping criterion has been reached.\n",
        "\n",
        "**step6**:To make a prediction for a new data point, traverse the tree starting from the root node and following the branches based on the values of the predictor variables until you reach a leaf node. The output of the leaf node is the predicted value for the new data point.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1zmBoJPJpG4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # import numpy package for arrays \n",
        "import pandas as pd # import pandas for importing csv files\n"
      ],
      "metadata": {
        "id": "m7xZaziii-kZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KSPCpghcg82l"
      },
      "outputs": [],
      "source": [
        "class CHAIDDecisionTreeRegressor:\n",
        "    \n",
        "    def __init__(self, max_depth=5, min_samples_split=2):\n",
        "        self.max_depth = max_depth  #determines the maximum depth of the decision tree that will be constructed\n",
        "        self.min_samples_split = min_samples_split #specifies the minimum number of samples required to split an internal node\n",
        "        self.tree = {}\n",
        "        self.best_params_ = {}\n",
        "   \n",
        "    def mse(self, y):\n",
        "        # Calculate mean squared error of targets\n",
        "        return np.mean((y - np.mean(y))**2)\n",
        "    \n",
        "    \n",
        "   \n",
        "    def split_data(self, feature, split, X, y):\n",
        "        left_indices = np.where(X[:, feature] < split) # find the indices of samples where the feature is less than the split value,(np.where)\n",
        "        right_indices = np.where(X[:, feature] >= split) # find the indices of samples where the feature is greater than or equal to the split value\n",
        "        X_left = X[left_indices] #create a new array of input samples for the left node using the left indices\n",
        "        y_left = y[left_indices] #create a new array of labels for the left node using the left indice\n",
        "        X_right = X[right_indices] # create a new array of input samples for the right node using the right indices\n",
        "        y_right = y[right_indices] # create a new array of labels for the right node using the right indices\n",
        "        return X_left, y_left, X_right, y_right # return the new input and label arrays for the left and right nodes\n",
        "   \n",
        "   \n",
        "    def chi_squared_test(self, x, y):\n",
        "        # Perform chi-squared test to determine if a split is significant\n",
        "        n_total = len(y) # calculate the total number of samples\n",
        "        n_left = len(np.where(x < x.mean())[0]) # calculate the number of samples in the left node (where x is less than the mean of x)\n",
        "        n_right = n_total - n_left # calculate the number of samples in the right node\n",
        "        p_left = n_left / n_total # calculate the proportion of samples in the left node\n",
        "        p_right = n_right / n_total # calculate the proportion of samples in the right node\n",
        "        y_left_mean = np.mean(y[x < x.mean()]) # calculate the mean of the labels for the samples in the left node\n",
        "        y_right_mean = np.mean(y[x >= x.mean()])  # calculate the mean of the labels for the samples in the right node\n",
        "        y_total_mean = np.mean(y) # calculate the mean of the labels for all the samples\n",
        "        chi_squared = (n_left * (y_left_mean - y_total_mean)**2 / (p_left * (1 - p_left)) +    # calculate the first part of the chi-squared test statistic\n",
        "                       n_right * (y_right_mean - y_total_mean)**2 / (p_right * (1 - p_right)))  # calculate the second part of the chi-squared test statistic\n",
        "        return chi_squared \n",
        "   \n",
        "    def find_split(self, X, y):\n",
        "        best_feature, best_split, best_chi2 = None, None, 0\n",
        "        n_features = X.shape[1] #This line finds the number of features in the feature matrix X\n",
        "        for feature in range(n_features): #sets up a loop that iterates over each feature in the input feature matrix X\n",
        "            for split in np.unique(X[:, feature]): #sets up a nested loop that iterates over the unique values of the feature \n",
        "                chi2 = self.chi_squared_test(X[:, feature], y) #passing in the values of the feature and target variable for the current split\n",
        "                if chi2 > best_chi2: \n",
        "                    best_feature, best_split, best_chi2 = feature, split, chi2 # chi-squared test statistic are stored in the best_feature, best_split, and best_chi2 variables.\n",
        "        return best_feature, best_split\n",
        "   \n",
        "   \n",
        "    def build_tree(self, X, y, depth):\n",
        "        # Recursively build the decision tree\n",
        "        n_samples, n_features = X.shape\n",
        "        # Check for stopping criteria\n",
        "        if depth == self.max_depth or n_samples < 2*self.min_samples_split:\n",
        "            leaf_value = np.mean(y)\n",
        "            return leaf_value\n",
        "        best_feature, best_split = self.find_split(X, y) #index of the best feature to split on and the best threshold to use for that feature\n",
        "        if best_feature is None:\n",
        "            leaf_value = np.mean(y)\n",
        "            return leaf_value\n",
        "        #The method returns four NumPy arrays: X_left and y_left, which contain the subset of the dataset\n",
        "        # where the feature value is less than or equal to the threshold, and X_right and y_right,\n",
        "        # which contain the subset of the dataset where the feature value is greater than the threshold\n",
        "        X_left, y_left, X_right, y_right = self.split_data(best_feature, best_split, X, y)\n",
        "        #This line is creating a Python dictionary called decision_node that represents a decision node in the decision tree\n",
        "        decision_node = {\"feature\": best_feature, \"split\": best_split, \"left\": None, \"right\": None}\n",
        "        decision_node[\"left\"] = self.build_tree(X_left, y_left, depth+1)# The value is the result of a recursive call to the build_tre\n",
        "        decision_node[\"right\"] = self.build_tree(X_right, y_right, depth+1)\n",
        "        return decision_node\n",
        "    \n",
        "    \n",
        "    def fit(self, X, y):\n",
        "          # Build the decision tree\n",
        "          self.tree = self.build_tree(X, y, depth=0)\n",
        "    \n",
        "    \n",
        "    def predict_single(self, x):\n",
        "        # Traverse the decision tree to make a prediction for a single instance\n",
        "        node = self.tree\n",
        "        while isinstance(node, dict):\n",
        "            if x[node[\"feature\"]] < node[\"split\"]:\n",
        "                node = node[\"left\"]\n",
        "            else:\n",
        "                node = node[\"right\"]\n",
        "        return node\n",
        "    \n",
        "    def predict(self, X):\n",
        "        # Make predictions for multiple instances\n",
        "        return np.array([self.predict_single(x) for x in X])\n",
        "    \n",
        "    # writing  function for r2_score (R2 = 1 - (SSres / SStot)) \n",
        "    def r2(self,y_true, y_pred):\n",
        "      # Calculate the mean of the true values\n",
        "      y_true_mean = sum(y_true) / len(y_true)\n",
        "      \n",
        "      # Calculate the total sum of squares (TSS)\n",
        "      tss = sum((y_true - y_true_mean) ** 2)\n",
        "      \n",
        "      # Calculate the residual sum of squares (RSS)\n",
        "      rss = sum((y_true - y_pred) ** 2)\n",
        "      \n",
        "      # Calculate the R-squared value\n",
        "      r2_score = 1 - (rss / tss)\n",
        "      \n",
        "      return r2_score\n",
        "\n",
        "\n",
        "    # To calaulate the MSE \n",
        "    def score(self,y_true, y_pred):\n",
        "   \n",
        "      # Check if the lengths of both arrays are equal\n",
        "      if len(y_true) != len(y_pred):\n",
        "          raise ValueError(\"Length of y_true and y_pred should be the same.\")\n",
        "      \n",
        "      # Calculate the squared differences between the true and predicted values\n",
        "      squared_differences = [(y_true[i] - y_pred[i])**2 for i in range(len(y_true))]\n",
        "      \n",
        "      # Calculate the mean of the squared differences\n",
        "      mse1 = sum(squared_differences) / len(squared_differences)\n",
        "      \n",
        "      return mse1\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def r2(y_true, y_pred):\n",
        "      # Calculate the mean of the true values\n",
        "      y_true_mean = sum(y_true) / len(y_true)\n",
        "      \n",
        "      # Calculate the total sum of squares (TSS)\n",
        "      tss = sum((y_true - y_true_mean) ** 2)\n",
        "      \n",
        "      # Calculate the residual sum of squares (RSS)\n",
        "      rss = sum((y_true - y_pred) ** 2)\n",
        "      \n",
        "      # Calculate the R-squared value\n",
        "      r2_score = 1 - (rss / tss)\n",
        "      \n",
        "      return r2_score"
      ],
      "metadata": {
        "id": "_GGSyIjsJUfr"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def mean_squared_error1(y_true, y_pred):\n",
        "   \n",
        "      # Check if the lengths of both arrays are equal\n",
        "      if len(y_true) != len(y_pred):\n",
        "          raise ValueError(\"Length of y_true and y_pred should be the same.\")\n",
        "      \n",
        "      # Calculate the squared differences between the true and predicted values\n",
        "      squared_differences = [(y_true[i] - y_pred[i])**2 for i in range(len(y_true))]\n",
        "      \n",
        "      # Calculate the mean of the squared differences\n",
        "      mse1 = sum(squared_differences) / len(squared_differences)\n",
        "      \n",
        "      return mse1"
      ],
      "metadata": {
        "id": "dZW-9SFQYA-D"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"HousingData.csv\")\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ShGHqKdxhbX_",
        "outputId": "d9592663-4e89-4174-c6e6-dd6362c645d3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
              "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
              "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
              "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
              "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
              "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
              "\n",
              "        B  LSTAT  MEDV  \n",
              "0  396.90   4.98  24.0  \n",
              "1  396.90   9.14  21.6  \n",
              "2  392.83   4.03  34.7  \n",
              "3  394.63   2.94  33.4  \n",
              "4  396.90    NaN  36.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a2fa1b6-2495-4753-a772-bc33dfc36b7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a2fa1b6-2495-4753-a772-bc33dfc36b7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a2fa1b6-2495-4753-a772-bc33dfc36b7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a2fa1b6-2495-4753-a772-bc33dfc36b7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "91Eae0eKls9N"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCySCA9SI7M9",
        "outputId": "eced4053-5e3b-470c-a331-6cef3ea07fb2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRIM       20\n",
              "ZN         20\n",
              "INDUS      20\n",
              "CHAS       20\n",
              "NOX         0\n",
              "RM          0\n",
              "AGE        20\n",
              "DIS         0\n",
              "RAD         0\n",
              "TAX         0\n",
              "PTRATIO     0\n",
              "B           0\n",
              "LSTAT      20\n",
              "MEDV        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.fillna(data.mean(),inplace=True)"
      ],
      "metadata": {
        "id": "7r0MkFq3bluA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.fillna(0)"
      ],
      "metadata": {
        "id": "TWvs1jqfeuAf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6ptI2JjJgUs",
        "outputId": "995ab24c-9b38-4606-f5dc-b5ba48683f0f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRIM       float64\n",
              "ZN         float64\n",
              "INDUS      float64\n",
              "CHAS       float64\n",
              "NOX        float64\n",
              "RM         float64\n",
              "AGE        float64\n",
              "DIS        float64\n",
              "RAD          int64\n",
              "TAX          int64\n",
              "PTRATIO    float64\n",
              "B          float64\n",
              "LSTAT      float64\n",
              "MEDV       float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "1Kc1cflzhe7W"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "-AZar6I0h4r7"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "YFDZ5xW7hnFd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=CHAIDDecisionTreeRegressor()"
      ],
      "metadata": {
        "id": "lRqIoY-ch9pQ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "BZBkXSwmiFuK"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "F3p3gnSxiNnd"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ma=mean_squared_error1(y_test,ypred)"
      ],
      "metadata": {
        "id": "wNYPTHh37K7w"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m1=r2(y_test,ypred)"
      ],
      "metadata": {
        "id": "hMd25C_-JlrF"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ma,m1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYwGdgVu7ssa",
        "outputId": "db7346e8-9075-4422-fa36-144b52a37f79"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87.86902660446587 -0.0007183897411384699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###Grid Search"
      ],
      "metadata": {
        "id": "urLSBuKUQXBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_search_cv(X, y, max_depth_range, min_samples_split_range, n_folds):\n",
        "    # Initialize the best score and best hyperparameters\n",
        "    best_score = -float(\"inf\")\n",
        "    best_max_depth = None\n",
        "    best_min_samples_split = None\n",
        "\n",
        "    # Loop through all the possible hyperparameters combinations\n",
        "    for max_depth in max_depth_range:\n",
        "        for min_samples_split in min_samples_split_range:\n",
        "            # Initialize the score for this hyperparameter combination\n",
        "            score = 0\n",
        "\n",
        "            # Loop through all the folds of cross-validation\n",
        "            for i in range(n_folds):\n",
        "                # Split the data into training and validation sets\n",
        "                val_indices = np.arange(i * len(X) // n_folds, (i + 1) * len(X) // n_folds)\n",
        "                train_indices = np.setdiff1d(np.arange(len(X)), val_indices)\n",
        "                X_train, y_train = X[train_indices], y[train_indices]\n",
        "                X_val, y_val = X[val_indices], y[val_indices]\n",
        "\n",
        "                # Initialize the decision tree regressor with the hyperparameters\n",
        "                tree = CHAIDDecisionTreeRegressor(max_depth=max_depth, min_samples_split=min_samples_split)\n",
        "\n",
        "                # Train the decision tree regressor on the training data\n",
        "                tree.fit(X_train, y_train)\n",
        "\n",
        "                # Evaluate the decision tree regressor on the validation data\n",
        "                score += tree.score(X_val, y_val)\n",
        "\n",
        "            # Calculate the average score for this hyperparameter combination\n",
        "            score /= n_folds\n",
        "            \n",
        "            # Update the best score and best hyperparameters if this score is better\n",
        "            if (score > best_score).any():\n",
        "                best_score = score\n",
        "                best_max_depth = max_depth\n",
        "                best_min_samples_split = min_samples_split\n",
        "             \n",
        "\n",
        "    # Initialize the decision tree regressor with the best hyperparameters\n",
        "    tree = CHAIDDecisionTreeRegressor(max_depth=best_max_depth, min_samples_split=best_min_samples_split)\n",
        "\n",
        "    # Train the decision tree regressor on the full data\n",
        "    tree.fit(X, y)\n",
        "  \n",
        "    \n",
        "    \n",
        "\n",
        "    return tree\n",
        "\n"
      ],
      "metadata": {
        "id": "8U_i0JVbK-8X"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_depths = [2, 3, 4,]\n",
        "min_samples_splits = [2, 5, 10]"
      ],
      "metadata": {
        "id": "UmHzCgPQOyLb"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v=grid_search_cv(X, y, max_depths, min_samples_splits, 5)"
      ],
      "metadata": {
        "id": "m82OJhYtMyAN"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2txeZ56GO7TP",
        "outputId": "2f10d9be-b3d3-4bde-f20d-05f97d52d1a5"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<__main__.CHAIDDecisionTreeRegressor object at 0x7fa81eed6640>, array([5.75457913e+02, 5.83534853e+02, 3.19678201e+02, 5.88838528e+02,\n",
            "       5.68982528e+02, 3.40372846e+02, 3.13839763e+03, 4.30718017e+02,\n",
            "       3.90189303e+02, 1.78239455e+05, 1.26064215e+02, 1.19562547e+05,\n",
            "       3.23258910e+02]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'max_depth': [2,3,4], 'min_samples_split': [2,3,5]}"
      ],
      "metadata": {
        "id": "7HRwnc7OmCQz"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Randomized search"
      ],
      "metadata": {
        "id": "X7t8pV8rvzSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools"
      ],
      "metadata": {
        "id": "ZrVvPiEJl5OK"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from random import randint\n",
        "# Define the hyperparameters to be tuned\n",
        "max_depth = [int(x) for x in np.linspace(2, 14, num = 11)]\n",
        "min_samples_split = [2, 4, 6, 8, 10,12]\n",
        "min_samples_leaf = [1, 2, 3, 4, 5,8,10]\n",
        "\n",
        "# Define the number of iterations for hyperparameter tuning\n",
        "n_iter = 20\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_folds = None\n",
        "\n",
        "# Define a function for k-fold cross-validation\n",
        "def k_fold_cv(X, y, model, n_folds):\n",
        "    # Initialize a dictionary to store the cross-validation scores\n",
        "    scores = defaultdict(list)\n",
        "\n",
        "    # Divide the data into k folds\n",
        "    fold_size = len(X) // n_folds\n",
        "    fold_starts = [i * fold_size for i in range(n_folds)]\n",
        "    fold_ends = [(i + 1) * fold_size for i in range(n_folds)]\n",
        "    fold_ends[-1] = len(X)\n",
        "\n",
        "    # Perform k-fold cross-validation\n",
        "    for i in range(n_folds):\n",
        "        # Split the data into training and validation sets\n",
        "        X_train = np.concatenate([X[:fold_starts[i]], X[fold_ends[i]:]])\n",
        "        y_train = np.concatenate([y[:fold_starts[i]], y[fold_ends[i]:]])\n",
        "        X_valid = X[fold_starts[i]:fold_ends[i]]\n",
        "        y_valid = y[fold_starts[i]:fold_ends[i]]\n",
        "\n",
        "        # Define the hyperparameters to be tuned\n",
        "        params = {'max_depth': max_depth[randint(0, len(max_depth)-1)],\n",
        "                  'min_samples_split': min_samples_split[randint(0, len(min_samples_split)-1)],\n",
        "                  'min_samples_leaf': min_samples_leaf[randint(0, len(min_samples_leaf)-1)]}\n",
        "\n",
        "        # Train the model with the current hyperparameters\n",
        "        model.set_params(**params)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate the model on the validation set\n",
        "        y_pred = model.predict(X_valid)\n",
        "        mse = mean_squared_error1(y_valid, y_pred)\n",
        "\n",
        "        # Store the cross-validation score\n",
        "        scores[mse].append(params)\n",
        "\n",
        "    # Return the best hyperparameters and the corresponding mean squared error\n",
        "    best_params = scores[min(scores)][0]\n",
        "    best_mse = min(scores)\n",
        "\n",
        "    return best_params, best_mse\n",
        "\n",
        "\n",
        "# Define the decision tree regressor model\n",
        "model1 = CHAIDDecisionTreeRegressor()\n",
        "\n",
        "# Perform the hyperparameter tuning using k-fold cross-validation and randomized search\n",
        "best_params, best_mse = k_fold_cv(X, y, model1, n_folds=10)\n",
        "\n",
        "# Print the best hyperparameters and the corresponding mean squared error\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "print(\"Best mean squared error:\", best_mse)"
      ],
      "metadata": {
        "id": "ReKTB_XFwq6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da90e91c-1f66-4e23-f00b-3c55e41eaac5"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 10}\n",
            "Best mean squared error: 21.52321345221607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "6xINuJFGawMK"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'max_depth': [5,3,4], 'min_samples_split': [6,3,5]}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4rBqVaAQkm9L"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6FQwepuaktUx"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fYQAvQ0WuMZW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}