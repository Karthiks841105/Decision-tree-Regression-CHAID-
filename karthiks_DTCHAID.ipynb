{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###DecisionTreeRegression(CHAID)\n",
        "####Decision tree regression using CHAID (Chi-squared Automatic Interaction Detection) is a popular algorithm for building regression trees. In this approach, the algorithm recursively partitions the data into smaller subsets based on the predictor variables that have the strongest association with the target variable."
      ],
      "metadata": {
        "id": "GjMV4Mp3eQtO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the step-by-step algorithm for decision tree regression:\n",
        "\n",
        "**step1**:Start with the entire dataset as the root node.\n",
        "\n",
        "**step2**:Choose a predictor variable that has a significant association with the target variable, and perform a chi-squared test to determine the best way to split the data into two subsets based on the values of that predictor variable.\n",
        "\n",
        "**step3**:If the chi-squared test indicates a significant difference between the subsets, create two child nodes and repeat steps 2-3 for each of the child nodes. If the chi-squared test does not indicate a significant difference, stop and make the current node a leaf node.\n",
        "\n",
        "**step4**:When creating child nodes, repeat the process until a stopping criterion is reached. This could be a maximum tree depth, a minimum number of samples in a leaf node, or a minimum improvement in the chi-squared statistic.\n",
        "\n",
        "**step5**:Continue building the tree until all the nodes have been split or the stopping criterion has been reached.\n",
        "\n",
        "**step6**:To make a prediction for a new data point, traverse the tree starting from the root node and following the branches based on the values of the predictor variables until you reach a leaf node. The output of the leaf node is the predicted value for the new data point.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1zmBoJPJpG4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # import numpy package for arrays \n",
        "import pandas as pd # import pandas for importing csv files\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "m7xZaziii-kZ"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "KSPCpghcg82l"
      },
      "outputs": [],
      "source": [
        "class CHAIDDecisionTreeRegressor:\n",
        "    \n",
        "    def __init__(self, max_depth=5, min_samples_split=2):\n",
        "        self.max_depth = max_depth  #determines the maximum depth of the decision tree that will be constructed\n",
        "        self.min_samples_split = min_samples_split #specifies the minimum number of samples required to split an internal node\n",
        "        self.tree = {}\n",
        "   \n",
        "   \n",
        "    \n",
        "    \n",
        "   \n",
        "    def split_data(self, feature, split, X, y):\n",
        "        left_indices = np.where(X[:, feature] < split) # find the indices of samples where the feature is less than the split value,(np.where)\n",
        "        right_indices = np.where(X[:, feature] >= split) # find the indices of samples where the feature is greater than or equal to the split value\n",
        "        X_left = X[left_indices] #create a new array of input samples for the left node using the left indices\n",
        "        y_left = y[left_indices] #create a new array of labels for the left node using the left indice\n",
        "        X_right = X[right_indices] # create a new array of input samples for the right node using the right indices\n",
        "        y_right = y[right_indices] # create a new array of labels for the right node using the right indices\n",
        "        return X_left, y_left, X_right, y_right # return the new input and label arrays for the left and right nodes\n",
        "   \n",
        "   \n",
        "    def chi_squared_test(self, x, y):\n",
        "        # Perform chi-squared test to determine if a split is significant\n",
        "        n_total = len(y) # calculate the total number of samples\n",
        "        n_left = len(np.where(x < x.mean())[0]) # calculate the number of samples in the left node (where x is less than the mean of x)\n",
        "        n_right = n_total - n_left # calculate the number of samples in the right node\n",
        "        p_left = n_left / n_total # calculate the proportion of samples in the left node\n",
        "        p_right = n_right / n_total # calculate the proportion of samples in the right node\n",
        "        y_left_mean = np.mean(y[x < x.mean()]) # calculate the mean of the labels for the samples in the left node\n",
        "        y_right_mean = np.mean(y[x >= x.mean()])  # calculate the mean of the labels for the samples in the right node\n",
        "        y_total_mean = np.mean(y) # calculate the mean of the labels for all the samples\n",
        "        chi_squared = (n_left * (y_left_mean - y_total_mean)**2 / (p_left * (1 - p_left)) +    # calculate the first part of the chi-squared test statistic\n",
        "                       n_right * (y_right_mean - y_total_mean)**2 / (p_right * (1 - p_right)))  # calculate the second part of the chi-squared test statistic\n",
        "        return chi_squared \n",
        "   \n",
        "    def find_split(self, X, y):\n",
        "        best_feature, best_split, best_chi2 = None, None, 0\n",
        "        n_features = X.shape[1] #This line finds the number of features in the feature matrix X\n",
        "        for feature in range(n_features): #sets up a loop that iterates over each feature in the input feature matrix X\n",
        "            for split in np.unique(X[:, feature]): #sets up a nested loop that iterates over the unique values of the feature \n",
        "                chi2 = self.chi_squared_test(X[:, feature], y) #passing in the values of the feature and target variable for the current split\n",
        "                if chi2 > best_chi2: \n",
        "                    best_feature, best_split, best_chi2 = feature, split, chi2 # chi-squared test statistic are stored in the best_feature, best_split, and best_chi2 variables.\n",
        "        return best_feature, best_split\n",
        "   \n",
        "   \n",
        "    def build_tree(self, X, y, depth):\n",
        "        # Recursively build the decision tree\n",
        "        n_samples, n_features = X.shape\n",
        "        # Check for stopping criteria\n",
        "        if depth == self.max_depth or n_samples < 2*self.min_samples_split:\n",
        "            leaf_value = np.mean(y)\n",
        "            return leaf_value\n",
        "        best_feature, best_split = self.find_split(X, y) #index of the best feature to split on and the best threshold to use for that feature\n",
        "        if best_feature is None:\n",
        "            leaf_value = np.mean(y)\n",
        "            return leaf_value\n",
        "        #The method returns four NumPy arrays: X_left and y_left, which contain the subset of the dataset\n",
        "        # where the feature value is less than or equal to the threshold, and X_right and y_right,\n",
        "        # which contain the subset of the dataset where the feature value is greater than the threshold\n",
        "        X_left, y_left, X_right, y_right = self.split_data(best_feature, best_split, X, y)\n",
        "        #This line is creating a Python dictionary called decision_node that represents a decision node in the decision tree\n",
        "        decision_node = {\"feature\": best_feature, \"split\": best_split, \"left\": None, \"right\": None}\n",
        "        decision_node[\"left\"] = self.build_tree(X_left, y_left, depth+1)# The value is the result of a recursive call to the build_tre\n",
        "        decision_node[\"right\"] = self.build_tree(X_right, y_right, depth+1)\n",
        "        return decision_node\n",
        "    \n",
        "    \n",
        "    def fit(self, X, y):\n",
        "          # Build the decision tree\n",
        "          self.tree = self.build_tree(X, y, depth=0)\n",
        "    \n",
        "    \n",
        "    def predict_single(self, x):\n",
        "        # Traverse the decision tree to make a prediction for a single instance\n",
        "        node = self.tree\n",
        "        while isinstance(node, dict):\n",
        "            if x[node[\"feature\"]] < node[\"split\"]:\n",
        "                node = node[\"left\"]\n",
        "            else:\n",
        "                node = node[\"right\"]\n",
        "        return node\n",
        "    \n",
        "    def predict(self, X):\n",
        "        # Make predictions for multiple instances\n",
        "        return np.array([self.predict_single(x) for x in X])\n",
        "    \n",
        "    # writing  function for r2_score (R2 = 1 - (SSres / SStot)) \n",
        "    def r2(self,y_true, y_pred):\n",
        "      # Calculate the mean of the true values\n",
        "      y_true_mean = sum(y_true) / len(y_true)\n",
        "      \n",
        "      # Calculate the total sum of squares (TSS)\n",
        "      tss = sum((y_true - y_true_mean) ** 2)\n",
        "      \n",
        "      # Calculate the residual sum of squares (RSS)\n",
        "      rss = sum((y_true - y_pred) ** 2)\n",
        "      \n",
        "      # Calculate the R-squared value\n",
        "      r2_score = 1 - (rss / tss)\n",
        "      \n",
        "      return r2_score\n",
        "\n",
        "\n",
        "    # To calaulate the MSE \n",
        "    def mean_squared_error(self,y_true, y_pred):\n",
        "   \n",
        "      # Check if the lengths of both arrays are equal\n",
        "      if len(y_true) != len(y_pred):\n",
        "          raise ValueError(\"Length of y_true and y_pred should be the same.\")\n",
        "      \n",
        "      # Calculate the squared differences between the true and predicted values\n",
        "      squared_differences = [(y_true[i] - y_pred[i])**2 for i in range(len(y_true))]\n",
        "      \n",
        "      # Calculate the mean of the squared differences\n",
        "      mse1 = sum(squared_differences) / len(squared_differences)\n",
        "      \n",
        "      return mse1\n",
        "    def score(self,y_true, y_pred):\n",
        "   \n",
        "      # Check if the lengths of both arrays are equal\n",
        "      if len(y_true) != len(y_pred):\n",
        "          raise ValueError(\"Length of y_true and y_pred should be the same.\")\n",
        "      \n",
        "      # Calculate the squared differences between the true and predicted values\n",
        "      squared_differences = [(y_true[i] - y_pred[i])**2 for i in range(len(y_true))]\n",
        "      \n",
        "      # Calculate the mean of the squared differences\n",
        "      mse1 = sum(squared_differences) / len(squared_differences)\n",
        "      \n",
        "      return mse1\n",
        "    \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"HousingData.csv\")\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ShGHqKdxhbX_",
        "outputId": "17085e51-c1f9-4cd6-95d6-dde9d0bcf5eb"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
              "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
              "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
              "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
              "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
              "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
              "\n",
              "        B  LSTAT  MEDV  \n",
              "0  396.90   4.98  24.0  \n",
              "1  396.90   9.14  21.6  \n",
              "2  392.83   4.03  34.7  \n",
              "3  394.63   2.94  33.4  \n",
              "4  396.90    NaN  36.2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c83535c-b457-4466-b398-f8cae5ee38b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MEDV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c83535c-b457-4466-b398-f8cae5ee38b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c83535c-b457-4466-b398-f8cae5ee38b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c83535c-b457-4466-b398-f8cae5ee38b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "91Eae0eKls9N"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCySCA9SI7M9",
        "outputId": "627c8beb-1e34-4037-e7e7-d5b22b2d36d5"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRIM       0\n",
              "ZN         0\n",
              "INDUS      0\n",
              "CHAS       0\n",
              "NOX        0\n",
              "RM         0\n",
              "AGE        0\n",
              "DIS        0\n",
              "RAD        0\n",
              "TAX        0\n",
              "PTRATIO    0\n",
              "B          0\n",
              "LSTAT      0\n",
              "MEDV       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.fillna(data.mean(),inplace=True)"
      ],
      "metadata": {
        "id": "7r0MkFq3bluA"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TWvs1jqfeuAf"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ab7Yti82ekdU"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6ptI2JjJgUs",
        "outputId": "fd2dcb12-843f-464d-9b09-d44ed038e7d1"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRIM       float64\n",
              "ZN         float64\n",
              "INDUS      float64\n",
              "CHAS       float64\n",
              "NOX        float64\n",
              "RM         float64\n",
              "AGE        float64\n",
              "DIS        float64\n",
              "RAD          int64\n",
              "TAX          int64\n",
              "PTRATIO    float64\n",
              "B          float64\n",
              "LSTAT      float64\n",
              "MEDV       float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a4k_tMkOJAge"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "1Kc1cflzhe7W"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BiivAdYLfhMZ"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bBAIxUEBfhAY"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "-AZar6I0h4r7"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "YFDZ5xW7hnFd"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Jw18E7v7lo-"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=CHAIDDecisionTreeRegressor()"
      ],
      "metadata": {
        "id": "lRqIoY-ch9pQ"
      },
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "BZBkXSwmiFuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518ff4f9-a320-4a40-e53c-fbbeb6bdb5b0"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred=model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "F3p3gnSxiNnd"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ma=model.mean_squared_error(y_test,ypred)"
      ],
      "metadata": {
        "id": "wNYPTHh37K7w"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYwGdgVu7ssa",
        "outputId": "b9154d8b-476c-46ea-a1f1-17e7b4a910cd"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74.43006886579745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###Grid Search"
      ],
      "metadata": {
        "id": "urLSBuKUQXBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "def grid_search(X, y, max_depth_range, min_samples_split_range, num_folds=5):\n",
        "    \"\"\"\n",
        "    Performs a grid search for decision tree regression.\n",
        "\n",
        "    Args:\n",
        "    - X: numpy array of shape (n_samples, n_features) containing the features of the dataset.\n",
        "    - y: numpy array of shape (n_samples,) containing the target variable of the dataset.\n",
        "    - max_depth_range: list of integers containing the range of values for the max_depth hyperparameter.\n",
        "    - min_samples_split_range: list of integers containing the range of values for the min_samples_split hyperparameter.\n",
        "    - num_folds: integer, the number of folds for cross-validation (default is 5).\n",
        "\n",
        "    Returns:\n",
        "    - best_params: dictionary containing the best hyperparameters found.\n",
        "    - best_score: float, the best mean squared error (MSE) found.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a list of all possible hyperparameter combinations\n",
        "    param_combinations = [(max_depth, min_samples_split) for max_depth in max_depth_range for min_samples_split in min_samples_split_range]\n",
        "\n",
        "    # Initialize best_score and best_params\n",
        "    best_score = float()\n",
        "    best_params = {}\n",
        "\n",
        "    # Iterate over all possible hyperparameter combinations\n",
        "    for params in param_combinations:\n",
        "        print(f\"Evaluating hyperparameters: {params}\")\n",
        "        mse_scores = []\n",
        "        for i in range(num_folds):\n",
        "            # Split the data into training and testing sets for cross-validation\n",
        "            indices = np.arange(len(X))\n",
        "            np.random.shuffle(indices)\n",
        "            X_shuffled = X[indices]\n",
        "            y_shuffled = y[indices]\n",
        "            fold_size = len(X) // num_folds\n",
        "            test_start = i * fold_size\n",
        "            test_end = (i + 1) * fold_size\n",
        "            X_test = X_shuffled[test_start:test_end]\n",
        "            y_test = y_shuffled[test_start:test_end]\n",
        "            X_train = np.concatenate((X_shuffled[:test_start], X_shuffled[test_end:]))\n",
        "            y_train = np.concatenate((y_shuffled[:test_start], y_shuffled[test_end:]))\n",
        "\n",
        "            # Train and evaluate the model with the given hyperparameters\n",
        "            model = CHAIDDecisionTreeRegressor(max_depth=params[0], min_samples_split=params[1])\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            mse_scores.append(mse)\n",
        "\n",
        "        # Compute the mean MSE over all folds\n",
        "        mean_mse = np.mean(mse_scores)\n",
        "\n",
        "        # Update best_score and best_params if the current hyperparameters have a better score\n",
        "        if mean_mse < best_score:\n",
        "            best_score = mean_mse\n",
        "            print(best_score)\n",
        "            best_params = {'max_depth': params[0], 'min_samples_split': params[1]}\n",
        "            print(best_params)\n",
        "            print(best_score)\n",
        "\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "p1rt9A0WQvRF"
      },
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth= [2, 3, 4 ]\n",
        "min_samples_split= [2, 4, 6]\n",
        "grid_search = grid_search(X,y,max_depth,min_samples_split,3)\n"
      ],
      "metadata": {
        "id": "iNXawQRjZGXJ"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0e3Ff8S5u9Ro"
      },
      "execution_count": 298,
      "outputs": []
    }
  ]
}